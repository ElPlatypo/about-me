<div class="grid">
  <div class="col-1 md:col-3"></div>
  <div class="central-column">
    <h1>Creating Digital Neurons</h1>
    <app-neural-network-visualizer
      [neuronsPerLayer]="[5, 7, 4, 2]"
      [neuronsActivations]="['relu', 'relu', 'sigmoid']"
      class="w-full"
    ></app-neural-network-visualizer>
    <p>
      After first learning about AI and Machine Learning, I decided that I
      wanted to know more about the subject. I was incredibly fascinated by it,
      yet also confused about how these algorithms work. Luckily for me, I found
      some good resources online that detailed the basics of machine learning,
      and I’d like to explain them here with a small interactive demo.
    </p>

    <h2>Basic Building Blocks: Weighted Sums</h2>
    <p>
      Although today’s machine learning algorithms are incredibly sophisticated,
      they can often be broken down to a simple concept: weighted sums. Let's
      break this down with an example. Imagine we have a series of three numbers
      A, B, and C, each associated with a "weight" value. Let's call these
      weights w<sub>A</sub>, w<sub>B</sub>, and w<sub>C</sub>. To calculate the
      value of C, we could use weighted sums like this:
    </p>
    <p>
      <strong>Equation:</strong> The value of C is calculated by first
      multiplying A by its weight w<sub>A</sub>, then multiplying B by its
      weight w<sub>B</sub>, and so forth:
    </p>
    <p>C = (A &times; w<sub>A</sub>) &times; w<sub>B</sub></p>
    <app-neural-network-visualizer
      [neuronsPerLayer]="[1, 1, 1]"
      class="w-full"
    ></app-neural-network-visualizer>
    <h2>Processing Multiple Inputs</h2>
    <p>
      In machine learning, algorithms usually take multiple inputs instead of a
      single number. Let’s say our input consists of a set of numbers, like
      A<sub>1</sub>, A<sub>2</sub>, and A<sub>3</sub>, each with their
      respective weights w<sub>A1</sub>, w<sub>A2</sub>, and w<sub>A3</sub>. We
      can compute a new value, B, as the sum of these weighted inputs:
    </p>
    <p>
      <strong>Equation:</strong>
    </p>
    <p>
      B = (A<sub>1</sub> &times; w<sub>A1</sub>) + (A<sub>2</sub> &times;
      w<sub>A2</sub>) + (A<sub>3</sub> &times; w<sub>A3</sub>)
    </p>
    <app-neural-network-visualizer
      [neuronsPerLayer]="[3, 1]"
      [neuronsActivations]="['sigmoid']"
      class="w-full"
    ></app-neural-network-visualizer>

    <h2>Expanding to Layers of Neurons</h2>
    <p>
      In a neural network, this process can be repeated across multiple steps,
      or "layers." Each layer is made up of values called "neurons." Suppose the
      first layer has N neurons (such as A<sub>1</sub>, A<sub>2</sub>, ...,
      A<sub>N</sub>). If the next layer contains K neurons (say B<sub>1</sub>,
      B<sub>2</sub>, ..., B<sub>K</sub>), each neuron in the first layer will
      have K weights associated with it (like w<sub>1A1</sub>, w<sub>2A1</sub>,
      ..., w<sub>KA1</sub>). These weights are used to compute the values of the
      next layer.
    </p>
    <app-neural-network-visualizer
      [neuronsPerLayer]="[3, 4, 3]"
      class="w-full"
    ></app-neural-network-visualizer>

    <h2>Controlling Output Ranges with Activation Functions</h2>
    <p>
      Both the initial values (such as A<sub>1</sub>, A<sub>2</sub>, ...,
      A<sub>N</sub>) and the weights in a network can be positive or negative.
      As these values move through each layer, they may increase or decrease
      drastically, potentially reaching very large positive or negative numbers.
      To keep these values within a manageable range, we apply an
      <strong>activation function</strong> to the output of each layer. An
      activation function "squeezes" values into a set range, often between 0
      and 1. For instance, if the output of a layer is very negative, the
      activation function will return a value close to 0; if it's positive and
      large, it returns a value closer to 1.
    </p>
    <p>
      With all of this in mind here's the first demo that lets you play with a
      fixed size network:
    </p>
    <app-neural-network-visualizer
      [neuronsPerLayer]="[3, 4, 2]"
      [playgroundMode]="true"
      class="w-full"
    ></app-neural-network-visualizer>
    <p>
      You might be confused right now by all the numbers and struggle to give
      them a meaning. to cement this example in reality with a real practical
      usage let's create a network that is able to recognize hand-written
      numbers.
    </p>
    <h2>Recognizing Written Numbers</h2>
    <p>
      Imagine we have a small image, 5x5 pixels in size, resulting in 25 total
      pixels. We’ll assume it’s a black-and-white image, allowing each pixel to
      be represented by 1 (black) or 0 (white).
    </p>
    <div class="flex flex-row justify-content-between w-full">
      <app-pixel-canvas
        [initArray]="canvasInits[0]"
        [showValues]="true"
      ></app-pixel-canvas>
      <app-pixel-canvas
        [initArray]="canvasInits[1]"
        [showValues]="true"
      ></app-pixel-canvas>
      <app-pixel-canvas
        [initArray]="canvasInits[2]"
        [showValues]="true"
      ></app-pixel-canvas>
    </div>
    <p>
      We can "unfold" our 5x5 grid of pixels into a linear array of 25 values,
      ranging from 0 to 1, and use this as input for a simple neural network.
    </p>
    <div
      class="flex flex-row justify-content-between align-items-center w-full"
    >
      <div class="w-full">
        <app-neural-network-visualizer
          [neuronsPerLayer]="[25, 10, 10, 10]"
          [neuronsActivations]="['relu', 'relu', 'sigmoid']"
          [inputDemo]="true"
        ></app-neural-network-visualizer>
      </div>
    </div>
    <p>
      In this demo, you can observe how changing the color of a pixel affects
      the output of the network. Here, we have 25 neurons as inputs, two hidden
      layers of 10 neurons each, and a final layer of 10 neurons.
    </p>
    <p>
      The choice of 10 neurons in the output layer is intentional: since we want
      the network to classify hand-written digits (0 through 9), we need 10
      possible outputs. Ideally, if a "5" is present in the image, the fifth
      neuron would have a higher value than the others.
    </p>
    <p>
      However, in real applications, the output isn’t always perfect. Instead of
      showing a clear answer, the network provides a "confidence" score for each
      possible digit. The output neuron with the highest value indicates the
      network's best guess for the digit in the image.
    </p>
    <h2>Why Training is Necessary</h2>
    <p>
      A neural network is essentially a series of mathematical functions
      connected in layers, each with weights that influence the output. However,
      when a network is first created, these weights are set randomly and don't
      actually "know" anything about the task at hand—whether it's recognizing
      handwritten numbers or predicting stock prices. This is where
      <strong>training</strong> becomes essential.
    </p>
    <p>
      During training, the network learns to adjust these weights in order to
      make accurate predictions. In the example of recognizing handwritten
      numbers, the network needs to learn patterns in pixel arrangements that
      correspond to each digit (0 through 9). To achieve this, the network goes
      through a process of adjustment and feedback that gradually improves its
      accuracy.
    </p>

    <h3>How Training Works in Recognizing Handwritten Numbers</h3>
    <p>
      Training a neural network typically involves a large dataset of labeled
      examples, known as <strong>training data</strong>. In our handwritten
      digit example, the dataset would contain thousands of 5x5 pixel images,
      each labeled with the correct digit (0-9) it represents.
    </p>
    <p>The training process follows these steps:</p>
    <ol>
      <li>
        <p>
          <strong>Forward Pass:</strong> Each image is fed into the network, and
          the network processes it to produce an output. In our case, this
          output is a list of confidence scores for each possible digit (0
          through 9).
        </p>
      </li>
      <li>
        <p>
          <strong>Calculate Error:</strong> The network compares its output to
          the correct answer (the label for the image). This difference, or
          <strong>error</strong>, tells the network how far off it was in
          identifying the digit.
        </p>
      </li>
      <li>
        <p>
          <strong>Backward Pass (Backpropagation):</strong> Using a technique
          called <strong>backpropagation</strong>, the network traces the error
          back through each layer and calculates how much each weight
          contributed to the error. This allows the network to adjust the
          weights to reduce future errors.
        </p>
      </li>
      <li>
        <p>
          <strong>Update Weights:</strong> Based on the error, the network
          adjusts its weights slightly to improve accuracy. This is done using a
          method called <strong>gradient descent</strong>, which helps the
          network move toward the optimal set of weights.
        </p>
      </li>
    </ol>

    <p>
      Through many iterations of this process—repeated for thousands or even
      millions of images—the network gradually "learns" the patterns associated
      with each digit. After enough training, it can accurately recognize
      handwritten numbers, even those it has never seen before. In the final
      stage, we test the network on new images to check its performance and make
      further adjustments if needed.
    </p>
    <p>
      In essence, training is what transforms a neural network from a simple
      mathematical structure into a powerful model that can identify, classify,
      or predict based on the patterns it has learned. Let's look at this
      concept in practice, in the next demo you will be able to train a
      initially randomized network with a dataset of examples i generated:
    </p>
  </div>
  <div class="col-1 md:col-3"></div>
</div>

<div class="grid flex align-items-center">
  <div class="col-12 md:col-3 custom-card m-0">
    <span>Train input visualizer</span>
    <app-pixel-canvas
      class="col-4"
      [initArray]="trainDemoNetwork.network.firstLayerBool"
      [size]="7"
    ></app-pixel-canvas>
    <span>Test network</span>
    <span
      *ngIf="
        trainDemoNetwork.trainprogress() > 0 &&
        trainDemoNetwork.trainprogress() < 100
      "
    >
      (disabled while training)
    </span>
    <app-pixel-canvas
      class="col-4"
      (outputArray)="trainDemoNetwork.evaluate($event)"
      [size]="7"
      [disabled]="
        trainDemoNetwork.trainprogress() > 0 &&
        trainDemoNetwork.trainprogress() < 100
      "
    ></app-pixel-canvas>
  </div>
  <app-neural-network-visualizer
    #trainDemoNetwork
    class="col-12 md:col-6"
    [neuronsPerLayer]="[49, 20, 10]"
    [trainMode]="true"
    [batchSize]="300"
    [expandHeight]="false"
  ></app-neural-network-visualizer>
  <div class="col-12 md:col-3 custom-card m-0">
    <p-chart
      type="line"
      [data]="trainDemoNetwork.lossForFraph()"
      [options]="lossChartOpts"
    />
  </div>
</div>

<div class="grid">
  <div class="col-1 md:col-3"></div>
  <div class="central-column">
    <p>sus</p>
  </div>
  <div class="col-1 md:col-3"></div>
</div>
